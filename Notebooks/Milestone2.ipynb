{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114cf9c2",
   "metadata": {},
   "source": [
    "# DSCI 525 - Web and Cloud Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfdb0d",
   "metadata": {},
   "source": [
    "In this milestone we move our project to the cloud. As part of this initiative, our team sets up a server in the cloud, a collaborative environment, and later moved data to the cloud. After that, we wrangled the data in preparation for machine learning.\n",
    "\n",
    "## Milestone 2 checklist  \n",
    "\n",
    "- To set up a collaborative environment:  \n",
    "    - [x] Setup your EC2 instance with JupyterHub.  \n",
    "    - [x] Install all necessary things needed in your UNIX server (amazon ec2 instance).\n",
    "    - [x] Set up your S3 bucket.  \n",
    "    - [x] Move the data that you wrangled in your last milestone to s3.  \n",
    "    - [x] To move data from s3.  \n",
    "- Wrangle the data in preparation for machine learning  \n",
    "    - [x] Get the data from S3 in your notebook and make data ready for machine learning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1884cb4",
   "metadata": {},
   "source": [
    "### 1. Setup your EC2 instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e80c45",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82539b2",
   "metadata": {},
   "source": [
    "#### Please attach this screen shots from your group for grading.\n",
    "![ec2](../Notebooks/images/EC2_instances.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ad5a3",
   "metadata": {},
   "source": [
    "### 2. Setup your JupyterHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f8283",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea6704",
   "metadata": {},
   "source": [
    "#### Please attach this screen shots from your group for grading\n",
    "I want to see all the group members here in this screenshot https://github.ubc.ca/mds-2021-22/DSCI_525_web-cloud-comp_students/blob/master/release/milestone2/image/2_result.png\n",
    "\n",
    "![jupyter](../Notebooks/images/hub_users.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801b911",
   "metadata": {},
   "source": [
    "### 3. Setup the server "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c732ef2d",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed70af",
   "metadata": {},
   "source": [
    "- [x] Add your team members to EC2 instance.\n",
    "\n",
    "- [x] Setup a common data folder to download data, and this folder should be accessible by all users in the JupyterHub.\n",
    "\n",
    "- [x] Install and configure AWS CLI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08693c0",
   "metadata": {},
   "source": [
    "#### Please attach this screen shots from your group for grading\n",
    "\n",
    "Make sure you mask the IP address refer [here](https://www.anysoftwaretools.com/blur-part-picture-mac/).\n",
    "\n",
    "https://github.ubc.ca/mds-2021-22/DSCI_525_web-cloud-comp_students/blob/master/release/milestone2/image/3_result.png\n",
    "\n",
    "![shared](../Notebooks/images/shared_data_folder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeecde21",
   "metadata": {},
   "source": [
    "### 4. Get the data what we wrangled in our first milestone. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174bec3",
   "metadata": {},
   "source": [
    "You have to install the packages that are needed. Refer this TLJH [document]( https://tljh.jupyter.org/en/latest/howto/env/user-environment.html).Refer ```pip``` section.\n",
    "\n",
    "Don't forget to add option -E. This way, all packages that you install will be available to other users in your JupyterHub.\n",
    "These packages you must install and install other packages needed for your wrangling.\n",
    "\n",
    "    sudo -E pip install pandas\n",
    "    sudo -E pip install pyarrow\n",
    "    sudo -E pip install s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d32fbd",
   "metadata": {},
   "source": [
    "As in the last milestone, we looked at getting the data transferred from Python to R, and we have different solutions. Henceforth, I uploaded the parquet file format, which we can use moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6a16f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b16325",
   "metadata": {},
   "source": [
    "Rememeber here we gave the folder that we created in Step 3.2 as we made it available for all the users in a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07bd98c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14226968  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"/srv/data/my_shared_data_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dae876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 26844650,\n",
       "  'name': 'allyears.csv.zip',\n",
       "  'size': 2405908113,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26844650',\n",
       "  'supplied_md5': '9e046ac05ecd2c32a256a47dd1098b81',\n",
       "  'computed_md5': '9e046ac05ecd2c32a256a47dd1098b81'},\n",
       " {'id': 26863682,\n",
       "  'name': 'individual_years.zip',\n",
       "  'size': 1896206676,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26863682',\n",
       "  'supplied_md5': '921da748974b07b2a70bbfcc04535a77',\n",
       "  'computed_md5': '921da748974b07b2a70bbfcc04535a77'},\n",
       " {'id': 27515426,\n",
       "  'name': 'combined_model_data.csv.zip',\n",
       "  'size': 821308997,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/27515426',\n",
       "  'supplied_md5': '7638434c44a7d29cbb29fe200b4fd65d',\n",
       "  'computed_md5': '7638434c44a7d29cbb29fe200b4fd65d'},\n",
       " {'id': 27520682,\n",
       "  'name': 'combined_model_data_parti.parquet.zip',\n",
       "  'size': 519743915,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/27520682',\n",
       "  'supplied_md5': '02f4e3df8d16580a02291de225072689',\n",
       "  'computed_md5': '02f4e3df8d16580a02291de225072689'},\n",
       " {'id': 27520808,\n",
       "  'name': 'combined_model_data.parquet',\n",
       "  'size': 565872005,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/27520808',\n",
       "  'supplied_md5': 'ae63699ab21ffa8006559c6afbcd2271',\n",
       "  'computed_md5': 'ae63699ab21ffa8006559c6afbcd2271'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ae9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_dl = [\"combined_model_data_parti.parquet.zip\"]  ## Please download the partitioned \n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11642663",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(output_directory, \"combined_model_data_parti.parquet.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2f04d9",
   "metadata": {},
   "source": [
    "### 5. Setup your S3 bucket and move data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c2bbf",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc337efd",
   "metadata": {},
   "source": [
    "- [x]  Create a bucket name should be mds-s3-xxx. Replace xxx with your \"groupnumber\".\n",
    "\n",
    "- [x]  Create your first folder called \"output\".\n",
    "\n",
    "- [x] Move the \"observed_daily_rainfall_SYD.csv\" file from the Milestone1 data folder to your s3 bucket from your local computer.\n",
    "\n",
    "- [x] Moving the parquet file we downloaded(combined_model_data_parti.parquet) in step 4 to S3 using the cli what we installed in step 3.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3e08c",
   "metadata": {},
   "source": [
    "#### Please attach this screen shots from your group for grading\n",
    "\n",
    "Make sure it has 3 objects.\n",
    "\n",
    "https://github.ubc.ca/mds-2021-22/DSCI_525_web-cloud-comp_students/blob/master/release/milestone2/image/4_result.png\n",
    "\n",
    "![s3](../Notebooks/images/S3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d40246",
   "metadata": {},
   "source": [
    "### 6. Wrangle the data in preparation for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ca7b4",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f1fca0",
   "metadata": {},
   "source": [
    "Our data currently covers all of NSW, but say that our client wants us to create a machine learning model to predict rainfall over Sydney only. There's a bit of wrangling that needs to be done for that:\n",
    "1. We need to query our data for only the rows that contain information covering Sydney\n",
    "2. We need to wrangle our data into a format suitable for training a machine learning model. That will require pivoting, resampling, grouping, etc.\n",
    "\n",
    "To train an ML algorithm we need it to look like this:\n",
    "\n",
    "||model-1_rainfall|model-2_rainfall|model-3_rainfall|...|observed_rainfall|\n",
    "|---|---|---|---|---|---|\n",
    "|0|0.12|0.43|0.35|...|0.31|\n",
    "|1|1.22|0.91|1.68|...|1.34|\n",
    "|2|0.68|0.29|0.41|...|0.57|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b4929d",
   "metadata": {},
   "source": [
    "6.1) Get the data from s3 (```combined_model_data_parti.parquet``` and ```observed_daily_rainfall_SYD.csv```)\n",
    "\n",
    "6.2) First query for Sydney data and then drop the lat and lon columns (we don't need them).\n",
    "```\n",
    "syd_lat = -33.86\n",
    "syd_lon = 151.21\n",
    "```\n",
    "Expected shape ```(1150049, 2)```.\n",
    "\n",
    "6.3) Save this processed file to s3 for later use:\n",
    "\n",
    "  Save as a csv file ```ml_data_SYD.csv``` to ```s3://mds-s3-xxx/output/```\n",
    "  expected shape ```(46020,26)``` - This includes all the models as columns and also adding additional column ```Observed``` loaded from ```observed_daily_rainfall_SYD.csv``` from s3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfa90e-0084-4c96-a486-24444fe65696",
   "metadata": {},
   "source": [
    "### Data wrangling code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbbe6d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.parse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be23c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_credentials = {\n",
    "    \"key\": \"ASIAWPZFFOX5GKHYY6E4\",\n",
    "    \"secret\": \"y2nn6f9/N2ArdPFh5wbI/aVRRRmqMG4VZu+x0YJH\",\n",
    "    \"token\" : \"FwoGZXIvYXdzEEYaDHjp2mp9ZMqDq8qNPSLNAUbBLpdgpEocOIvBaqF+4+l5ZT/5QuDXjVegeTftVhAHxkRtFtHi0Mm3x7dtr5PTtzgELMl6Nv9GDm/KP47Zjv4N2g8jO3Ox73GWGaR8TdBBvRtqxxGthqfUuLJ5k/uDHLe2/Di4MrBCGa4vyq3WQFKmcvRE/Eh/6WlAxqWkXcXRnzhnLnfC+v8jRP/JmkWgj/VP416jBOS0KIlgXRXaHEO6zSR+dFtgSutdIjBeX8aQfxOwxDplNArb85kV7wGah3bMtxi1DZtznZkRWZIojfC+kgYyLauupVOOa94H1MC5KEU7dGn2JXKrIjVTkVg/sdzeTAwVsR1MQh+pLzLnGzZNcA==\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77ea33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading observed rainfall csv dataset from s3\n",
    "observed = pd.read_csv('s3://mds-s3-arlincherian/observed_daily_rainfall_SYD.csv',\n",
    "                    storage_options = aws_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "581da8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading combined data parquet file from s3\n",
    "df = pd.read_parquet('s3://mds-s3-arlincherian/output/model=CMCC-CM2-HR4/bd6cc563dd314a97bc8e98274d16be49.parquet',\n",
    "                    storage_options = aws_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fef8f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>1.162277e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>4.016328e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>1.639138e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>2.554377e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>6.764351e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    lat_min   lat_max  lon_min  lon_max  rain (mm/day)\n",
       "0 1889-01-01 12:00:00 -35.811518 -34.86911  140.625  141.875   1.162277e+00\n",
       "1 1889-01-02 12:00:00 -35.811518 -34.86911  140.625  141.875   4.016328e+00\n",
       "2 1889-01-03 12:00:00 -35.811518 -34.86911  140.625  141.875   1.639138e-17\n",
       "3 1889-01-04 12:00:00 -35.811518 -34.86911  140.625  141.875   2.554377e-20\n",
       "4 1889-01-05 12:00:00 -35.811518 -34.86911  140.625  141.875   6.764351e-03"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37f359b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining lat and long of Sydney for filtering\n",
    "syd_lat = -33.86\n",
    "syd_lon = 151.21\n",
    "\n",
    "df_syd = df.query(\"lat_min <= @syd_lat and lat_max >= @syd_lat and \\\n",
    "                   lon_min <= @syd_lon and lon_max >= @syd_lon\")\n",
    "df_syd = df_syd.drop(columns=[\"lat_min\", \"lat_max\", \"lon_min\", \"lon_max\"])\n",
    "\n",
    "# selecting observed raninfall model from the second dataset\n",
    "observed[\"model\"] = \"observed_rainfall\"\n",
    "\n",
    "# combining dataset\n",
    "df_concat = pd.concat([df_syd, observed])\n",
    "df_concat[\"time\"] = pd.to_datetime(df_concat[\"time\"]).dt.date\n",
    "df_concat.set_index(\"time\", inplace=True)\n",
    "\n",
    "# new dataset output\n",
    "ml_df = df_concat.pivot(values=\"rain (mm/day)\", columns=\"model\").reset_index().drop(columns=[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cd4e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataset to output folder on s3\n",
    "ml_df.to_csv(\"s3://mds-s3-arlincherian/output/ml_data_SYD.csv\", storage_options = aws_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fbbce5",
   "metadata": {},
   "source": [
    "How the final file format looks like\n",
    "https://github.ubc.ca/mds-2021-22/DSCI_525_web-cloud-comp_students/blob/master/release/milestone2/image/finaloutput.png\n",
    "\n",
    "Shape ```(46020,26 )```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578c8c1",
   "metadata": {},
   "source": [
    "(***OPTIONAL***) If you are interested in doing some benchmarking!! How much time it took to read..\n",
    "- Parquet file from your local disk ?\n",
    "- Parquet file from s3 ?\n",
    "- CSV file from s3 ?\n",
    "    For that, upload the CSV file (```combined_model_data.csv```\n",
    "     )to S3 and try to read it instead of parquet. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
